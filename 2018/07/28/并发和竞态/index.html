<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.3.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.3.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.3.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '6.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="android-boot-img-结构">
<meta property="og:type" content="article">
<meta property="og:title" content="并发和竞态">
<meta property="og:url" content="http://yoursite.com/2018/07/28/并发和竞态/index.html">
<meta property="og:site_name" content="Semiyd&#39;s Blog">
<meta property="og:description" content="android-boot-img-结构">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2018-07-28T08:14:53.434Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="并发和竞态">
<meta name="twitter:description" content="android-boot-img-结构">






  <link rel="canonical" href="http://yoursite.com/2018/07/28/并发和竞态/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>并发和竞态 | Semiyd's Blog</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Semiyd's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />Home</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />Categories</a>
  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/28/并发和竞态/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Semiyd">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Semiyd's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">并发和竞态
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-07-28 15:19:59 / Modified: 16:14:53" itemprop="dateCreated datePublished" datetime="2018-07-28T15:19:59+08:00">2018-07-28</time>
            

            
              

              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a></span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Linux/Kernel/" itemprop="url" rel="index"><span itemprop="name">Kernel</span></a></span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Linux/Kernel/并发和竞态/" itemprop="url" rel="index"><span itemprop="name">并发和竞态</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><center><strong>android-boot-img-结构</strong></center><br><a id="more"></a><br>==============================================并发和竞态===================================<br>1.编译乱序<br>    编译乱序是指，c代码的顺序正确，但编译的时候，编译器为了提高性能，会试图打乱顺序，编译出和实际c代码执行顺序不同的汇编代码。<br>    内存屏障API</p>
<pre><code>#define barrier() __asm__ __volatile__(&quot;&quot;: : :&quot;memory&quot;)
#define mb() barrier()
#define rmb() mb()
#define wmb() mb()
从定义可以看出，以上所有的接口，其实就是一漂戏。内部就是同一句代码。
至于这句代码，是在c语言里面嵌入汇编的语句。具体的嵌入汇编涉及的语法，在下面的原子操作的部分，有详细的解释。
    嵌入汇编的格式是：asm(code : output operand list : input operand list : clobber list)
    简单来说，就是其实code，output operand list，input operand list都是空的。只有clobber list是memory。
    这里的memory就是告知gcc，在汇编代码中，我修改了memory中的内容，嵌入式汇编之前的c代码块和嵌入式汇编之后的c代码块看到的memory是不一样的，
    对memory的访问不能依赖于嵌入式汇编之前的c代码块中寄存器的内容，需要重新加载。 

例子1：
desc-&gt;word0 = address;
wmb();
desc-&gt;word1 = DESC_VALID;
这里的wmb的功能是，保证了屏障之前的写操作一定会在后来的写操作执行之前完成，不会编译乱序（例如硬件上需要先得到某个字节的更新，然后得到后面那个字节的更新）
类似的还有rmb，是指读操作。
mb指令保证了读写两者都不会

例子2：
以关抢占来保护临界区为例：
preempt_disable()
临界区 
preempt_enable()
所谓的preempt enable和disable其实就是对当前进程的struct thread_info中的preempt_count进行加一和减一的操作。具体的代码如下： 
#define preempt_disable() \ 
 do { \ 
     preempt_count_inc(); \ 
     barrier(); \ 
 } while (0)  
注意到这里就用到了barrier()。barrier就象是c代码中的一个栅栏，将代码逻辑分成两段，barrier之前的代码和barrier之后的代码在经过编译器编译后顺序不能乱掉。
假设这里没有加barrier()，如果编译为了榨取CPU的performace而对汇编指令进行重排，那么临界区的代码就有可能位于preempt_count_inc之外，从而起不到保护作用。 

例子3：
当你的驱动调用printk的时候，实际上最终是通过console的write函数输出到了串口控制台。
这个console write的函数会包含下面的代码：
do { 
     获取TX FIFO状态寄存器 
    barrier(); 
 } while (TX FIFO没有ready); 
写TX FIFO寄存器; 
对于ARM来说，外设硬件的IO地址也被映射到了一段内存地址空间，对编译器而言，它并不知道这些地址空间是属于外设的。
如果没有barrier的话，编译的过程中，获取TX FIFO状态寄存器的指令可能和写TX FIFO寄存器指令进行重新排序，
在这种情况下，程序逻辑就不对了，因为我们必须要保证TX FIFO ready的情况下才能写TX FIFO寄存器。 

实际的定义位于：（4.4内核）
arch\arm\include\asm\barrier.h
实际的定义比上面的介绍要复杂些。针对不同的arm架构还有不同的内核配置，定义会有所不同。

memory barrier相关的API列表如下： 
    接口名称      作用  
    barrier()          优化屏障，阻止编译器为了进行性能优化而进行的memory access reorder  
    mb()          内存屏障（包括读和写），用于SMP和UP  
    rmb()          读内存屏障，用于SMP和UP  
    wmb()          写内存屏障，用于SMP和UP  
    smp_mb()      用于SMP场合的内存屏障，对于UP不存在memory order的问题（对汇编指令），因此，在UP上就是一个优化屏障，确保汇编和c代码的memory order是一致的  
    smp_rmb()      用于SMP场合的读内存屏障  
    smp_wmb()      用于SMP场合的写内存屏障  



有关读取寄存器的时候，防止乱序的问题
    参考Documentation/io_ordering.txt
    __iowmb()和__iormb()
类似mb()，只是这是针对io的mb()
读写寄存器的readl_relaxed()和readl()的区别就体现在有无__iormb()这块。
见arch\arm\include\asm\io.h        
#define readb(c)        ({ u8  __v = readb_relaxed(c); __iormb(); __v; })
#define readw(c)        ({ u16 __v = readw_relaxed(c); __iormb(); __v; })
#define readl(c)        ({ u32 __v = readl_relaxed(c); __iormb(); __v; })

#define writeb(v,c)        ({ __iowmb(); writeb_relaxed(v,c); })
#define writew(v,c)        ({ __iowmb(); writew_relaxed(v,c); })
#define writel(v,c)        ({ __iowmb(); writel_relaxed(v,c); })

#define readb_relaxed(c) ({ u8  __r = __raw_readb(c); __r; })
#define readw_relaxed(c) ({ u16 __r = le16_to_cpu((__force __le16) \
                __raw_readw(c)); __r; })
#define readl_relaxed(c) ({ u32 __r = le32_to_cpu((__force __le32) \
                __raw_readl(c)); __r; })

#define writeb_relaxed(v,c)    __raw_writeb(v,c)
#define writew_relaxed(v,c)    __raw_writew((__force u16) cpu_to_le16(v),c)
#define writel_relaxed(v,c)    __raw_writel((__force u32) cpu_to_le32(v),c)

总的来说。编译乱序就是指，因为编译器的原因。导致执行上的乱序。编译好以后，顺序就已经乱掉了。

barrier()这个函数，从cpu内部硬件上是如何实现的细节，参见“Linux内核同步机制之（三）：memory barrier.pdf”的2、cpu architecture和cache的组织     这一段有详尽的解释，涉及cache操作的细节。
</code></pre><p>2.指令乱序<br>    指令乱序是指，编译成汇编机器码以后，就算没有乱序，在执行的时候，cpu会根据实际情况决定是否乱序执行。<br>    下面就单核和多核两种不同的情形，针对执行顺序的优化进行介绍：<br>    单核：<br>        考虑下面的例子：<br>        LDR    r0,    [r1];<br>        STR    r2,    [r3];<br>        假设LDR的时候，指令缓存未命中。这时候，指令缓存就会去做填充行的动作，并且需要比较多个时钟周期。<br>        armv5及以前的处理器，会等待这一过程完毕，然后再去执行STR。<br>        armv6及以后的处理器，会识别出，下一条指令STR，并不依赖上一条执行LDR的结果（这种情况称为未遇到”依赖点“）。从而安排STR执行提前执行。<br>        如此就产生了一个指令的乱序。<br>        对于单核的情况，程序员无需关心这一细节。因为这种指令乱序，在单核cpu上发生的时候，如果没遇到依赖点，则会乱序。如果遇到依赖点，则会等待。<br>        所以说，对程序员来说，这种单核的乱序是不可见的。<br>    多核：<br>        刚刚说了单核的指令乱序。对于遇到依赖点的情况，在单核上，cpu会自动等待。<br>        但如果依赖点变成，如果一个核cpu1，去依赖了cpu0的某个执行结果呢？<br>        问题就在于，这种跨越核的依赖，默认cpu1是看不到cpu0的情况的，也就是说cpu1并不知道自己其实依赖着cpu0的某个步骤。<br>        考虑下面这个具体的例子：<br>        core 0                     core 1<br>        Write A;                    Load B;<br>        Write B;                    Load A;<br>         假设core 0，write A的时候，发生Cache Miss，所以会直接去先执行write B。那么就会导致在cache中 A的最新值更新慢于B的最新值。<br>        于是在core1中的指令Load B就会拿到新值，而Load A 就会拿到旧值。<br>        如果A与B有相互关系的话，便可能产生死锁等问题。<br>        解决办法是：<br>        core 0                     core 1<br>        Write A;                    Load B;<br>        DMB;                    Load A;<br>        Write B;<br>        DMB的作用：DMB前面的LOAD/STORE读写的最新值的acknowledgement在时间上一定先于DMB之后的指令。总之就是DMB之前的指令，肯定会等待完成。<br>        这种汇编级别支持的硬件指令，一共有下面三种：<br>        DMB,DSB,ISB<br>        Data Memory Barrier(DMB)<br>        Data Synchronization Barrier(DSB)<br>        Instruction Synchronization Barrier(ISB)<br>        DSB 和DMB容易混淆。他们的区别在于：DMB可以继续执行之后的指令，只要这条指令不是内存访问指令。而DSB不管它后面的什么指令，都会强迫CPU等待它之前的指令执行完毕。<br>        其实在很多处理器设计的时候，DMB和DSB没有区别（DMB完成和DSB同样的功能）。<br>        ISB不仅做了DSB所做的事情，还将流水线清空。于是他们的重量级排序可以是：ISB&gt;DSB&gt;DMB<br>    以上内容详见内核的Documentation/memory-barriers.txt</p>
<p>3.临界区：<br>    临界区就是进程之间可能会发生冲突的数据区域。<br>    进程之间，其实数据地址空间，是独立的。<br>    所以理论上，其实仅仅是用户空间的话，进程之间，不存在临界区。<br>    临界区在哪？<br>        临界区一定位于内核空间。要么是内核的数据结构，要么是某种硬件寄存器资源。<br>    那么其实针对临界区的一些加锁的保护，都是内核的API。进程是没法直接调用的。所以使用锁的API，要不是内核代码，要不是内核驱动。<br>        那么进程，是通过系统调用，来真正调用这些内核的代码的。<br>        所以如果涉及临界区，加锁，解锁，其实一定涉及系统调用。<br>    只有进程通过系统调用，进入内核空间，才可能去访问临界区。<br>    而抢占是什么？抢占说白了，就是不等一个进程的系统调用（内核态）完成，就去做另外一个高优先级进程的事情（用户态）。对于临界区的访问，如果这时候不加以保护，就会发生冲突。<br>    换句话说，对于单核cpu，只要禁掉抢占，就可以保证，在不同优先级的用户进程之间，就不会有临界区发生冲突的问题。（见下面有关spinlock单核的情况）<br>    但这里仅仅是指在不同优先级的用户进程之间，能这样关抢占来保护。在单核的不同的内核线程之间（例如数个同时运行的workqueue），则spinlock起不到保护临界区的作用。（见下面有关spinlock的介绍）<br>    对于多核cpu，则禁掉本地的抢占，并不能直接阻止别的核上的程序，通过系统调用来访问临界区，还需要进一步的保护（比如说让别的核 死等，详见下面有关spinlock多核的情况解释）</p>
<p>4.屏蔽中断以避免一部分竞态的情形<br>    local_irq_disable()<br>    …<br>    critical section<br>    …<br>    local_irq_enable()<br>    以上这种做法，可以防止中断处理程序和进程之间的并发。并且因为内核的进程调度是依赖中断的。所以保护区内，进程调度被禁止，进程之间的并发也可以避免。<br>    local_irq_disable()的原理，是屏蔽ARM处理器CPSR处理器的I位。<br>    见arch\arm\include\asm\irqflags.h<br>    static inline void arch_local_irq_disable(void)<br>    {<br>        asm volatile(<br>            “    cpsid i            @ arch_local_irq_disable”<br>            :<br>            :<br>            : “memory”, “cc”);<br>    }<br>    但是，这种屏蔽中断来获得安全临界区的方法，有两个问题：<br>    a.Linux的异步I/O，进程调度等很多操作都依赖中断。长期屏蔽中断的话，会导致数据丢失甚至系统崩溃。所以临界区里面的操作必须快。<br>    b.这个方法针对多核SMP的情况无效。只能屏蔽本cpu核的中断，无法解决SMP情况下的竞态问题。</p>
<p>5.锁机制：<br>    原子操作<br>        所谓原子操作，就是指内核提供了一系列的API，来完成一些特定的操作，比如把某个变量加减，然后再判断值是否等于0.<br>        你只要使用这些API，如果能运行成功，就能保证整个操作是原子的。如果真的被以外打断，那也不会破坏数据，只会返回操作失败。<br>        实现的原理：<br>            ARMv6及其之前，不支持SMP，都是通过关闭中断来完成的。<br>                static inline int atomic_add_return(int i, atomic_t *v)<br>                 {<br>                     unsigned long flags;<br>                     int val; </p>
<pre><code>                raw_local_irq_save(flags); 
                 val = v-&gt;counter; 
                 v-&gt;counter = val += i; 
                 raw_local_irq_restore(flags); 

                return val; 
             } 
        ARMv6之后：
            /*
             * ARMv6 UP and SMP safe atomic ops.  We use load exclusive and
             * store exclusive to ensure that these are atomic.  We may loop
             * to ensure that the update happens.
             */
            static inline void atomic_add(int i, atomic_t *v)
            {
                unsigned long tmp;
                int result;

                __asm__ __volatile__(&quot;@ atomic_add\n&quot;
            &quot;1:    ldrex    %0, [%3]\n&quot;
            &quot;    add    %0, %0, %4\n&quot;
            &quot;    strex    %1, %0, [%3]\n&quot;
            &quot;    teq    %1, #0\n&quot;
            &quot;    bne    1b&quot;
                : &quot;=&amp;r&quot; (result), &quot;=&amp;r&quot; (tmp), &quot;+Qo&quot; (v-&gt;counter)
                : &quot;r&quot; (&amp;v-&gt;counter), &quot;Ir&quot; (i)
                : &quot;cc&quot;);
            }
            为了说明上一段代码的内容，先说下c语言里面嵌入汇编的写法：
            原始的格式是：
            asm(code : output operand list : input operand list : clobber list)
            asm是GNU的扩展。__asm__也是GNU的扩展，作用一样。
            这里的__volatile__主要是用来防止编译器优化的。如果你的嵌入式汇编使用__asm__ __volatile__(嵌入式汇编)的语法格式，
            那么也就是告诉编译器，不要随便动我的嵌入汇编代码。
            那么，上面这种嵌入汇编的格式，解释如下：
            1.分为code : output operand list : input operand list : clobber list四部分。每个部分用引号:来分开。
            2.code就是汇编代码的主体，每一行用&quot;&quot;双引号包起来，结尾用\n表示换行。
            3.output operand list是刚刚的code会修改的变量，中间用逗号,隔开。
            4.input operand list是刚刚的code会读取的入参，中间用逗号,隔开。
            5.clobber list是除了output operand list以外，code部分还会修改到的寄存器/变量等，需要通知gcc，否则会影响后续c语言的正常执行。
            那么，在code里面，可以看到很多%0 %1这样的符号。这个其实是代指output operand list和input operand list里面的变量的编号。
            编号规则是这样的。
            因为是output operand在前，input operand在后。
            那么按照变量出现的次序，依次从%0开始编号。以上面的代码为例：
            (result),(tmp)，(v-&gt;counter)，(&amp;v-&gt;counter)，(i)分别对应：
            %0,%1,%2,%3,%4，并出现在code中。
            对于output operand list，必须符合这个格式：[ [asmSymbolicName] ] constraint (cvariablename)
                asmSymbolicName就是个代称。将来可以在code里面去使用，假设名字叫[aaa]，那么code里面，就可以%[aaa]这样来引用。
                如果asmSymbolicName没有定义，则将采用上面说到的，直接%0这样用序号来引用。例如上面的atomic_add就没有定义asmSymbolicName。
                contraint需要以=号或者+号开始。=号表示仅仅会写，不会去读，+号表示会读和写（具体含义不理解）
                在=号或者+号之后，r表示变量在寄存器里，m表示变量在内存里。    rm可以组合，表示交由编译器决定最优的方案。
                r的意思就是告诉编译器，帮我选择一个通用寄存器保存该操作数吧。
                另外，&amp;也是constraint，表示告诉GCC，不要把输出变量，去覆盖掉之前放输入值的寄存器。
                    具体原因是。GCC有时候，会认为，输入值，读了以后，就没用了。此时处于优化的原因，可以在函数执行完以后，把输出的值，放在原来
                    存放输入值的寄存器Rn里面。
            对于input operand list，必须符合这个格式：[ [asmSymbolicName] ] constraint (cexpression)
                asmSymbolicName同output operand list里面的定义。
                constraint 和输出不同，不以=或者+号开头。r表示变量在寄存器里，m表示变量在内存里。rm可以组合，表示交由编译器决定最优的方案。
                &quot;Ir&quot; (i)，这里“I”这个限制符对应ARM平台，表示这是一个有特定限制的立即数，
                    该数必须是0～255之间的一个整数通过rotation的操作得到的一个32bit的立即数。
                    对于ARM来说，每个指令32个bit，其中12个bit被用来表示立即数，其中8个bit是真正的数据，4个bit用来表示如何rotation。
            对于clobber list
                clober list是gcc和gas的接口，用于gas通知gcc它对寄存器和memory的修改情况。
                一般都填cc。通知gcc，嵌入式汇编代码更新了condition code register。 
            所以
            注意：
                不要尝试在不使用input operand list的情况下，在汇编里面去访问比如c语言的全局变量。
            现在回到主题也就是ldrex和strex
            ldr和str这两条指令大家都是非常的熟悉了，后缀的ex表示Exclusive，是ARMv7提供的为了实现同步的汇编指令。 
            LDREX  &lt;Rt&gt;, [&lt;Rn&gt;]    也就是读取操作
                &lt;Rn&gt;是base register，保存memory的address，LDREX指令从base register中获取memory address，
                且将memory的内容加载到&lt;Rt&gt;(destination register)中
                这些操作和ldr的操作是一样的，那么如何体现exclusive呢？
                其实，在执行这条指令的时候，还放出两条“狗”来负责观察特定地址的访问（就是保存在[&lt;Rn&gt;]中的地址了）
                这两条狗一条叫做local monitor，一条叫做global monitor。
            STREX &lt;Rd&gt;, &lt;Rt&gt;, [&lt;Rn&gt;]    也就是写入操作
                和LDREX指令类似，&lt;Rn&gt;是base register，保存memory的address，STREX指令从base register中获取memory address，
                并且将&lt;Rt&gt; (source register)中的内容加载到该memory中。
                这里的&lt;Rd&gt;保存了memeory 更新成功或者失败的结果，0表示memory更新成功，1表示失败。
                STREX指令是否能成功执行是和local monitor和global monitor的状态相关的。
                对于Non-shareable memory（该memory不是多个CPU之间共享的，只会被一个CPU访问），只需要放出该CPU的local monitor这条狗就OK了
                下面的表格可以描述这种情况 
                thread 1      thread 2      local monitor的状态  
                                      Open Access state  
                LDREX                 Exclusive Access state  
                           LDREX          Exclusive Access state  
                           Modify          Exclusive Access state  
                           STREX          Open Access state  
                Modify                 Open Access state  
                STREX                 在Open Access state的状态下，执行STREX指令会导致该指令执行失败  
                                      保持Open Access state，直到下一个LDREX指令  
            这个表格表示的情况是这样的。假设有一个thread1。他的本意是对某个数据进行更改。使用了原子操作。
            那么，在thread1用LDREX获取数据后（写之前肯定要先读出来），这时候突然因为某种原因，被thread2打断了。
            thread2一下子完成了LDREX，修改，STREX这一系列读然后写入的操作。    
            这时候，标志位local monitor因为thread2的STREX的执行，被置为Open Access state  
            此时thread1才有机会修改并STREX。但是在Open Access state的状态下，执行STREX指令会导致该指令执行失败 。
            原因是，STREX执行的时候，如果之前没被打断，肯定应该还在Exclusive Access state
            但此时既然是Open Access state，就意味着有别人（thread2）对刚刚的数据进行了修改。
            这时候如果thread1的STREX继续执行，会导致冲掉thread2的写入的数据.
            所以这个时候thread1的原子操作就会失败返回。保证了操作的原子性。
            那么结合atomic_add的真实代码。可以看到，如果失败，就bne 1b，也就是跳转到标签1处，也就是重新开始一次新的写入的尝试。

            说白了就是。真正写入数据，是由STREX执行的。而不是普通的Store指令。这个指令很特殊，不符合原子操作的条件下，是没法写成功的。

            另外，对于shareable memory，需要系统中所有的local monitor和global monitor共同工作，完成exclusive access，概念类似，这里就不再赘述了。 

    主要用于实现资源计数
    atomic_set(),atomic_inc(),atomic_dec()
    原子操作运用的实例：
    static atomic_t xxx_available = ATOMIC_INIT(1);    定义原子变量，并初始化为1.
    static int xxx_open(...)        设备的open()函数的定义
        {
            if(!atomic_dec_and_test(&amp;xxx_available))    {    把原子量（初始值为1）减一，然后如果是0，则返回1，如果是非0，则返回0.
                atomic_inc(&amp;xxx_available);            所以如果设备已经有人打开，这时候再atomic_dec_and_test，原子量是-1，所以需要恢复原子量的值
                return -EBUSY;                也就是atomic_inc再加回去，然后返回错误，因为这意味着设备已经被打开了。
                }
            ...    做具体的open设备的操作
            return 0;
        }
    static int xxx_close(...)        设备的close()函数的定义
        {
            atomic_inc(&amp;xxx_available);                设备关闭，原子量可以恢复成1了。（相当于资源计数）
            return 0;
        }
    以上的例子，说明了两点。一就是原子量通常的作用，也就是资源计数。二是，在对原子量操作的过程中，是安全的，不用特别的保护，只需使用atomic_xxx的API，就可以保证原子操作。

    代码位置：
        arch\arm\include\asm\atomic.h
自旋锁                                -用于中断/进程上下文
    计划：
        看http://www.wowotech.net/kernel_synchronization/spinlock.html
        看书

    几个特点：
    spinlock是一种死等的锁机制。也就是说，某个进程尝试获取spinlock失败时，会不停的尝试获取锁。
    spinlock和信号量不同，信号量可以允许多于一个的锁持有者进入临界区。spinlock只允许一个锁持有者进入临界区
    spinlock适合临界区代码很短的情形。否则临界区代码太长，会导致别的申请获得锁的进程一直在死等，浪费cpu资源。
        （ARM提供了WFE和SEV这样的类似指令，避免CPU进入busy loop的悲惨境地，后面会介绍）
    spinlock可以在中断里面运行。


    spinlock获取锁期间，当前cpu，内核会禁掉抢占。原因是：
        之前介绍临界区的概念的时候，其实已经说明了为什么要这样做。
        对于spinlock，其实要分UP和SMP两种情况讨论的。
        UP:
            对于UP，其实spinlock加锁的过程，就是关掉抢占。并没必要去死等，也没有死等的代码实现。
            如果不关掉抢占，就没法保证对临界区的保护了。因为随时会被别的高优先级进程打断，高优先级进程再进系统调用，就可能访问需要保护的临界区。
            如果UP，内核又不支持抢占的情况，自然不用关闭抢占了。所以spinlock()会退化成空操作。
                当然这时候如果涉及中断里面访问临界区的情况，还是要关中断的。如spin_lock_irqsave()。    
            总结下来，就是对于单核的情况，其实spinlock并不会真的导致cpu忙等待。
        SMP:
            对于多核。其实除了UP的关抢占，还需要进一步的操作，让别的核的CPU死等（WFE和SEV），才能真正实现对临界区的保护。

    另外，如果需要在中断里面获取spinlock，又在进程里面要用spinlock。则进程里面的spinlock需要和禁止本cpu中断的API一起组合使用（如spin_lock_irqsave()）。原因是：
        假设某个进程持有了spinlock在访问临界资源。    
        这个时候本cpu来了个中断。中断里面也需要访问临界资源。
        但因为spinlock已被进程持有。导致中断里面一直在死等自旋。又因为出不了中断，导致进程的spinlock无法释放。造成死锁。
        当然其实如果是多核的情况，非本地cpu发生中断，是没关系的。因为非本地的cpu，会在非本地的cpu中断里面自旋，但并不妨碍本地cpu把临界区访问完，然后释放spinlock。
        再多说一句，就是如果是在中断的底半部分使用spinlock。那其实只用禁止底半部分中断就可以了。
        另外，这种中断和进程同时访问临界区的情形。为了安全起见，中断里面是要用spinlock()函数的。
            如果是UP。那么假设正常情况下，进程里面已经用了spin_lock_irqsave()。意味着进程访问临界区的时候，其实没有中断可以进来打断。
                中断又不能嵌套，所以没关系，中断里面可以不用spinlock()函数.
            如果是SMP，即使进程里面已经用了spin_lock_irqsave()，也不能阻止非本地的cpu核进中断。这时候就要求非本地的cpu核在中断里面自旋一会。
                所以中断里面必须spinlock()函数.
            所以总体来说，为了兼容性起见，驱动里面的中断，还是加上spinlock()函数为好。即使目前暂时是跑在UP平台上的。

    中断之间竞争spinlock的情形分析：
        1.硬件中断之间进行竞争
            假设有两种不同的硬件中断。都需要访问同一个临界资源。
            因为2.6.35以后的新内核，中断是没有嵌套的。所以中断处理过程中，内核本身就是关中断的。所以涉及在中断里面获取spinlock的时候，并不需要特别去关闭中断。
            总之就是这种情况，什么都不用做。
        2.底半部分之softirq
            假设只有一种softirq要访问临界资源。
            同一个softirq，会到不同的cpu核上运行。支持并发，也就是可以重入。
            这时候，即使是只有一种softirq要访问临界资源，对于多核cpu的情况，也需要加spinlock保护下。
            而且，softirq其实是中断上下文。所以和上面的“硬件中断之间进行竞争”原因一样，不用特别去关闭中断。
        3.底半部分之tasklet之间
            假设只有一种tasklet要访问临界资源。
            同一个tasklet，并不能在不同的cpu核上并发，也不会在同一个cpu上并发。（也就是不支持重入）
            所以如果是临界资源的访问仅存在于tasklet。则无需加spinlock。因为tasklet本身是不会并发的。（当然如果进程中还要访问临界资源，那肯定就要加spinlock了）
            再多说一句。如果共享资源只在两个或者多个tasklet/timer上访问。则无需使用spin_lock_bh。原因同样是因为tasklet/timer不会在同一个cpu上并发。

    内核线程之间，竞争spinlock的情形分析：
        详见最后面的实践部分。
        对于UP，那么之前讲了，spinlock退化成关抢占。但是内核线程之间，不存在抢占的问题。（抢占是针对不同的优先级的用户进程之间而言的。）
            所以UP上，如果开了数个内核线程，比如数个work queque，这些work queue都会访问同一个临界区的话。
            那么用spinlock来保护是没用的。这时候只能用semaphore。
        对于SMP，可以正常用spinlock进行保护。

    代码的实现：
        体系无关的部分代码：
            include/linux/spinlock_types.h    
                这个头文件定义了通用spin lock的基本的数据结构（例如spinlock_t）和如何初始化的接口（DEFINE_SPINLOCK）。
                这里的“通用”是指不论SMP还是UP都通用的那些定义。
            include/linux/spinlock_types_up.h
                这个头文件不应该直接include，在include/linux/spinlock_types.h文件会根据系统的配置（是否SMP）include相关的头文件，
                如果UP则会include该头文件。
                这个头文定义UP系统中和spin lock的基本的数据结构和如何初始化的接口。
            include/linux/spinlock.h
                这个头文件定义了通用spin lock的接口函数声明，例如spin_lock、spin_unlock等，使用spin lock模块接口API的驱动模块或者其他内核模块都需要include这个头文件。 
            include/linux/spinlock_up.h
                这个头文件不应该直接include，在include/linux/spinlock.h文件会根据系统的配置（是否SMP）include相关的头文件。这个头文件是debug版本的spin lock需要的。 
            include/linux/spinlock_api_up.h
                同上，只不过这个头文件是non-debug版本的spin lock需要的 
            linux/spinlock_api_smp.h
                SMP上的spin lock模块的接口声明 
            kernel/locking/spinlock.c
                SMP上的spin lock实现。 
            这块的代码结构是很凌乱的。而且分UP还是SMP，debug还是non-debug。我觉得作为内核使用者来说，稍作了解即可。
            稍作整理如下：（摘自include/linux/spinlock.h的注释部分）
            UP需要的头文件              SMP需要的头文件  
            linux/spinlock_type_up.h:         asm/spinlock_types.h 
            linux/spinlock_types.h:         linux/spinlock_types.h: 
             linux/spinlock_up.h:         asm/spinlock.h 
             linux/spinlock_api_up.h:         linux/spinlock_api_smp.h:
             linux/spinlock.h             linux/spinlock.h 

            数据结构：
                一个spinlock_t的数据类型，其本质上是一个整数值（对该数值的操作需要保证原子性），该数值表示spin lock是否可用。
                初始化的时候被设定为1。当thread想要持有锁的时候调用spin_lock函数，该函数将spin lock那个整数值减去1，然后进行判断，如果等于0，
                表示可以获取spin lock，如果是负数，则说明其他thread的持有该锁，本thread需要spin。 
                内核中的spinlock_t的定义如下：
                typedef struct spinlock {
                    union {
                        struct raw_spinlock rlock;
                    };
                } spinlock_t;
                那么struct raw_spinlock的定义如下：
                typedef struct raw_spinlock {
                    arch_spinlock_t raw_lock;
                } raw_spinlock_t;
                这个arch_spinlock_t，是和平台相关的定义。下面会解释。

            API接口：
                接口API的类型                      spinlock中的定义          raw_spinlock的定义  

                定义spin lock并初始化                  DEFINE_SPINLOCK      DEFINE_RAW_SPINLOCK  
                动态初始化spin lock                  spin_lock_init          raw_spin_lock_init  
                获取指定的spin lock                  spin_lock          raw_spin_lock  
                获取指定的spin lock同时disable本CPU中断          spin_lock_irq          raw_spin_lock_irq  
                保存本CPU当前的irq状态，                  spin_lock_irqsave          raw_spin_lock_irqsave  
                      disable本CPU中断并获取指定的spin lock
                获取指定的spin lock同时disable本CPU的bottom half      spin_lock_bh          raw_spin_lock_bh      用于timer/tasklet里面涉及获取锁
                释放指定的spin lock                  spin_unlock          raw_spin_unlock  
                释放指定的spin lock同时enable本CPU中断          spin_unlock_irq          raw_spin_unock_irq  
                释放指定的spin lock同时恢复本CPU的中断状态          spin_unlock_irqstore      raw_spin_unlock_irqstore  
                获取指定的spin lock同时enable本CPU的bottom half      spin_unlock_bh          raw_spin_unlock_bh  
                尝试去获取spin lock，如果失败
                      不会spin，而是返回非零值            spin_trylock          raw_spin_trylock  
                判断spin lock是否是locked，如果其他的thread已经    spin_is_locked          raw_spin_is_locked  
                    获取了该lock，那么返回非零值，否则返回0  

            以spin_lock()的代码，来看下里面如何实现的：
                static inline void spin_lock(spinlock_t *lock)
                {
                    raw_spin_lock(&amp;lock-&gt;rlock);
                }
                那么：
                #define raw_spin_lock(lock)    _raw_spin_lock(lock)
                那么：_raw_spin_lock()的定义，其实根据UP还是SMP，是不一样的。
                UP:（在spinlock_api_up.h）
                    #define _raw_read_lock(lock)            __LOCK(lock)    
                    #define __LOCK(lock) \
                      do { preempt_disable(); __acquire(lock); (void)(lock); } while (0)
                    # define __acquire(x) (void)0
                    在UP单核的情况下，spinlock仅仅是关闭的抢占，就足以保护临界区。具体原因上面的段落已经解释过了。
                SMP:（在spinlock_api_smp.h）
                    #define _raw_spin_lock(lock) __raw_spin_lock(lock)
                    static inline void __raw_spin_lock(raw_spinlock_t *lock)
                    {
                        preempt_disable();
                        spin_acquire(&amp;lock-&gt;dep_map, 0, 0, _RET_IP_);
                        LOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);
                    }
                    在SMP的情况下。当然首先是关抢占，解决本地cpu的冲突。    
                    那么在这个基础上，还要做这么两件事情：
                    spin_acquire(&amp;lock-&gt;dep_map, 0, 0, _RET_IP_);
                        spin_acquire可以略过，这是和运行时检查锁的有效性有关的，如果没有定义CONFIG_LOCKDEP其实就是空函数。
                    LOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock); 
                        LOCK_CONTENDED就是核心所在了。
                        #define LOCK_CONTENDED(_lock, try, lock) \
                            lock(_lock)
                        也就是执行do_raw_spin_lock()
                        static inline void do_raw_spin_lock(raw_spinlock_t *lock) __acquires(lock)
                        {
                            __acquire(lock);
                            arch_spin_lock(&amp;lock-&gt;raw_lock);
                        }
                        __acquire()和静态代码检查有关，无视。
                        可以看到，这里涉及的arch_spin_lock()，就到了真正和架构相关的部分了。下面来介绍。
        体系架构相关的部分代码：
            arch/arm/include/asm/spinlock.h
                定义了具体ARM架构上，spinlock相关API的具体实现。
            arch/arm/include/asm/spinlock_type.h
                定义了arch_spinlock_t结构体
            重点就是arch_spin_lock()的实现。
            因为存在历史沿革问题，体系相关代码的分析，需要分为老内核和新内核两部分来解释。
            老内核：（2.6.23前后，简要介绍。重点介绍新内核的细节）
                2.6.23内核里的定义：
                typedef struct {
                    volatile unsigned int lock;
                } raw_spinlock_t;//那时候还是使用raw_spinlock_t而不是arch_spinlock_t
                2.6.39的内核里的定义：
                typedef struct {
                    volatile unsigned int lock;
                } arch_spinlock_t;
                都差不多。
                总之就是，spinlock就是一个整数来维护。0表示无锁，1表示有锁。
                配套的API包括__raw_spin_lock和__raw_spin_unlock。
                __raw_spin_lock会持续判断lock的值是否等于0，如果不等于0（locked）那么其他thread已经持有该锁，
                本thread就不断的spin，判断lock的数值，一直等到该值等于0为止，一旦探测到lock等于0，那么就设定该值为1，表示本thread持有该锁了，
                当然，这些操作要保证原子性，细节和exclusive版本的ldr和str（即ldrex和strexeq）相关，这里略过。
                离开临界区后，持锁thread会调用__raw_spin_unlock函数解锁。
                这种做法最大的问题，就是不公平。
                在单核时代，对锁的竞争不太激烈的时候，没问题。
                到了多核，很多个进程对锁竞争，无序的争抢spin lock，谁先抢到谁先得，不管thread等了很久还是刚刚开始spin。
                测试表明，在8核的机器上，很多个进程竞争锁，有个进程居然饥饿的等待1000000次。
            新内核：
                4.4内核里的定义：
                typedef struct { 
                     union { 
                         u32 slock; 
                         struct __raw_tickets { 
                             u16 owner; 
                             u16 next; 
                         } tickets; 
                     }; 
                 } arch_spinlock_t; 
                可以看到，相比早期的版本，新的spinlock结构体，内容已经和老的完全不一样了。    
                这里引入的是ticket-based spin lock的概念。
                比方就是出去吃饭，遇到排队，要领号。这里的ticket就是号。
                即使临界区资源可以申请，也要根据排队的号来申领。
                回到arch_spinlock_t。owner就是当前已经入席的那个号码，也就是当前持有锁的那个人的号码。
                next记录的是下一个要分发的号码。
                至于slock，可以看到这其实是个union数据类型。所以slock其实是owner加上next的合体。
                典型的情景如下：
                1.一开始的时候，slock是0.也就是说owner和next都是0.owner和next相等，表示未加锁。
                2.第一个进程申请spinlock，并且让next++。(owner=0|next=1)假设第一个进程用完了临界区，释放了锁。此时把owner++。(owner=1|next=1)
                3.这时候又来了个进程，要申请spinlock.这时候因为之前的进程已经解锁了。所以现在这个进程没排队，直接领号1，并且获得锁，next++。(owner=1|next=2)
                4.假设owner1这个进程，动作非常慢。后面来的进程，申请spinlock失败，则马上领号2(因next=2)，并把next++.(owner=1|next=3)
                5.假设owner1还在占用锁。再后面来的就从3号开始领号。领一次号，next++。3，4，5，6.。。。如此继续排队。
                6.owner1解锁。这时候紧跟着排队的owner2才有资格获得锁。

            代码实现（以新内核+v6以后的32位ARM为例分析）
            static inline void arch_spin_lock(arch_spinlock_t *lock) 
             { 
                 unsigned long tmp; 
                 u32 newval; 
                 arch_spinlock_t lockval; 

                prefetchw(&amp;lock-&gt;slock);－－－－－－－－－－－－－－－－－－－－－－－－（1） 
                __asm__ __volatile__( 
             &quot;1:    ldrex    %0, [%3]\n&quot;－－－－－－－－－－－－－－－－－－－－－－－－－（2） 
            &quot;    add    %1, %0, %4\n&quot; 
             &quot;    strex    %2, %1, [%3]\n&quot;－－－－－－－－－－－－－－－－－－－－－－－－（3） 
            &quot;    teq    %2, #0\n&quot;－－－－－－－－－－－－－－－－－－－－－－－－－－－－（4） 
            &quot;    bne    1b&quot; 
                 : &quot;=&amp;r&quot; (lockval), &quot;=&amp;r&quot; (newval), &quot;=&amp;r&quot; (tmp) 
                 : &quot;r&quot; (&amp;lock-&gt;slock), &quot;I&quot; (1 &lt;&lt; TICKET_SHIFT) 
                 : &quot;cc&quot;); 

                while (lockval.tickets.next != lockval.tickets.owner) {－－－－－－－－－－－－（5） 
                    wfe();－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－（6） 
                    lockval.tickets.owner = ACCESS_ONCE(lock-&gt;tickets.owner);－－－－－－（7） 
                } 

                smp_mb();－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－（8） 
            } 
            （1）和preloading cache相关的操作，主要是为了性能考虑，不是重点。 
            （2）将&amp;lock-&gt;slock的值，通过ldrex保存在lockval这个临时变量中 。注意这里用了ldrex和strex，来保证操作原子性。
            （3）将spin lock中的next加一。同样为原子操作的指令。strex。
            （4）判断是否有其他的thread插入刚刚的ldrex和strex原子操作。如果说没有人打断刚刚的原子操作，至此就完成了next++这个领号的动作。
            （5）判断当前spin lock的状态，如果是unlocked，那么直接获取到该锁 
            （6）如果当前spin lock的状态是locked，那么调用wfe进入等待状态。注意这里并非真的用white(1)循环去傻傻地等。
                wfe其实本质上是让当前执行这个指令的cpu核，进入低功耗状态等待。当别的cpu核执行了SEV指令（当spinlock解锁时），会唤醒其他cpu核。
                这样子，相比老内核+老的ARM核，傻傻的while循环去等。wfe至少做到了把功耗降下来，硬件上进入休眠。（详见下面针对WFE的解释）
            （7）其他的CPU通过SEV指令唤醒了本cpu的执行，说明owner发生了变化，该新的own赋给lockval，然后继续判断spin lock的状态，也就是回到step 5。 
                换句话说。如果某个cpu核，释放了锁。这时候通知所有等待锁的cpu核起床了。起床后，更新当前的owner，再各自检查下，是不是轮到自己了。
                是自己，就去干活。不是自己，接着睡觉。
                另外。这里用到了ACCESS_ONCE()，详见下面的解释.
                顺便看一眼，解锁spinlock的时候，是怎么发出SEV指令的：
                static inline void arch_spin_unlock(arch_spinlock_t *lock)
                {
                    smp_mb();    //内存屏障相关
                    lock-&gt;tickets.owner++;
                    dsb_sev();
                }
                可以看到，除了owner++的动作。还有个语句就是dsb_sev();。
                static inline void dsb_sev(void)
                {
                    dsb(ishst);    //指令乱序相关
                    __asm__(SEV);
                }
                __asm__(SEV);就是SEV指令所在了。
            （8）memory barrier的操作，不是重点。

            上面的代码是32位的ARM.那么最新的64位ARM，是怎么实现的？
            arch\arm64\include\spinlock.h
            static inline void arch_spin_lock(arch_spinlock_t *lock)
            {
                unsigned int tmp;
                arch_spinlock_t lockval, newval;

                asm volatile(
                /* Atomically increment the next ticket. */
                ARM64_LSE_ATOMIC_INSN(
                /* LL/SC */
            &quot;    prfm    pstl1strm, %3\n&quot;
            &quot;1:    ldaxr    %w0, %3\n&quot;
            &quot;    add    %w1, %w0, %w5\n&quot;
            &quot;    stxr    %w2, %w1, %3\n&quot;
            &quot;    cbnz    %w2, 1b\n&quot;,
                /* LSE atomics */
            &quot;    mov    %w2, %w5\n&quot;
            &quot;    ldadda    %w2, %w0, %3\n&quot;
            &quot;    nop\n&quot;
            &quot;    nop\n&quot;
            &quot;    nop\n&quot;
                )

                /* Did we get the lock? */
            &quot;    eor    %w1, %w0, %w0, ror #16\n&quot;
            &quot;    cbz    %w1, 3f\n&quot;
                /*
                 * No: spin on the owner. Send a local event to avoid missing an
                 * unlock before the exclusive load.
                 */
            &quot;    sevl\n&quot;
            &quot;2:    wfe\n&quot;
            &quot;    ldaxrh    %w2, %4\n&quot;
            &quot;    eor    %w1, %w2, %w0, lsr #16\n&quot;
            &quot;    cbnz    %w1, 2b\n&quot;
                /* We got the lock. Critical section starts here. */
            &quot;3:&quot;
                : &quot;=&amp;r&quot; (lockval), &quot;=&amp;r&quot; (newval), &quot;=&amp;r&quot; (tmp), &quot;+Q&quot; (*lock)
                : &quot;Q&quot; (lock-&gt;owner), &quot;I&quot; (1 &lt;&lt; TICKET_SHIFT)
                : &quot;memory&quot;);
            }
            总的来说就是ARM64的指令，其实相比ARM32的指令，变化还是很多的。
            详细的分析以后有时间再一句一句看。
                32位的ldrex进化成了ldaxr.这个新指令被称为Load-Acquire/Store-Release。这是ARMv8的新指令。
                意思是执行load和store操作的时候顺便执行了memory barrier相关的操作.

            相关知识之WFE指令（也介绍下WFI指令）
                WFI(Wait for interrupt)和WFE(Wait for event)是两个让ARM核进入low-power standby模式的指令
                主要是“将ARM PE(Processing Element, 处理单元)设置为low-power standby state”。
                WFI/WFE的区别：
                    WFI来说，执行WFI指令后，ARM core会立即进入low-power standby state，直到有WFI Wakeup events发生。
                    而WFE则稍微不同，执行WFE指令后，根据Event Register（一个单bit的寄存器，每个PE一个）的状态，有两种情况：
                    如果Event Register为1，该指令会把它清零，然后执行完成（不会standby）；如果Event Register为0，和WFI类似，    
                    进入low-power standby state，直到有WFE Wakeup events发生。
                    所以说，WFI和WFE，在入睡的条件上，是不一样的。
                    在唤醒的条件上，也略有不同：
                    WFI唤醒条件：
                        收到WFI wakeup event
                        IRQ各种中断
                    WFE唤醒条件：
                        收到WFE wakeup event
                        IRQ各种中断
                        但注意，WFE可以被任何PE（也就说从任何一个cpu核上）上执行的SEV指令，所产生的wakeup event唤醒。
                所谓的SEV指令，就是一个用来改变Event Register的指令，有两个：SEV会修改所有PE上的寄存器；SEVL，只修改本PE的寄存器值。

            相关知识之ACCESS_ONCE()    
                #define ACCESS_ONCE(x) (*(volatile typeof(x) *)&amp;(x))
                从定义就可以看出，ACCESS_ONCE()其实就是加了个volatile。
                使用ACCESS_ONCE修饰过的语句，编译器就被告知，不要去优化这句话。
    自旋锁使用不当的几种情况举例：
    1.禁止递归使用自旋锁。一个已经获得锁的进程，如果再次申请锁，会造成死锁。
    2.获取锁后，不能在调用引起进程调度的函数。比如copy_from_user(),kmalloc(),mseelp()。原因比较复杂。详见“Linux内核：spinlock和睡眠.pdf”
        简单来说，首先spinlock本来就要求快速访问完临界区。这时候去睡眠，从逻辑上就不合理。
        细说的话，“Linux内核：spinlock和睡眠.pdf”讨论了几种单/多核+开/关抢占的情形。但结论都是不应该睡眠。“Linux内核：spinlock和睡眠.pdf”文中已经有详细说明。

    UP情况下，中断里面，无论如何是无需spinlock的？
        假设是中断之间竞争锁。那么中断里面是关中断禁止嵌套的，各个中断自然都无需上锁。
        假设是线程和中断之间竞争锁。那么首先这时候线程上锁，就已经需要关中断。
            如果线程先占有的锁，这时候因为用了诸如spin_lock_irqsave来关中断，那么中断就进不来。中断自然不用上锁。
            如果是中断先访问的临界区，即使是抢占式内核，也要等到中断返回，线程才有机会再次去访问临界区，而这时候中断早退出了。
        综合之下似乎是这么个考虑。

信号量                                -仅能用于进程上下文，会导致睡眠
    分两种，semaphore和mutex
    不能用于中断(除了down_trylock())
    如果是可以多次进入的信号量，则用sema_init初始化。如果是只能进入一次的互斥量，则用DECLARE_MUTEX初始化。
    mutex_lock()，mutex_unlock()
    down(),up()
    down_interruptible()    
        睡眠过程中，如果获得信号（如kill信号），则醒来返回一个错误的值-EINTR    
        这个和down()的区别是，万一产生死锁，至少还能接收外部的例如kill的信号，这样能用ctrl+C来杀死进程。
    down_trylock()，这个不会引起睡眠，可以在中断里面使用，是个特例。如果获取锁失败，就返回错误。
    这里面mutex就是轻量级的semaphore，就是semaphore的简化版。所以有以下的限制：
        1）同一时间只能有一个进程获得锁，这是互斥的概念。
        2）只能在同一进程上锁和解锁，而信号量不一样，可以在这个进程上锁，另外的进程解锁。
        3）同一个进程获得锁后这段期间不能再获得这个锁，也就是说不能递归使用，原因很简单，因为是互斥，上锁的只有一次，只能解锁有在上锁。
        4）进程持有锁是不能退出。
        5）中断上下文不能使用锁，即使是mutex_trylock()。
        6）互斥锁只能通过内核提供的API接口来操作。
读写锁    
    读者之间无竞争，写者是独占性的，会合其他的读者和写者竞争。适用于很多读者和少量写者的情况，如路由表的访问。
    read_lock(),read_unlock(),write_lock(),write_unlock()
    read_lock_irqsave()类似于spin_lock_irqsave()的变种
顺序锁（写者不会阻塞）
    读写锁的变种，除了读写锁的功能以外，还能保证写的时候还能读，只是写的时候不能再来一个写的人。
    和读写锁相比，适用于写者不希望被读者阻塞的情况。例如读取jiffies_64的函数u64 get_jiffies_64(void)
    同时，因为读的时候可以写，那么这种读写同时发生的情况，有一个unsigned sequence变量来提示是不是读的时候有人在写，
    如果有，那就要多读一次或者几次
    write_seqlock_irqsave
    read_seqbegin_irqsave
读-拷贝-修改锁（读者不会被阻塞）RCU锁
    写的时候，先写到一个拷贝出来的副本。等所有读者退出以后，再写。还有读者的时候，就睡眠，等所有读者读完再唤醒。
    这样读者不会被阻塞。
Completion Interface
    用于同步，也是一种锁机制。
    发出completion的一方：
        DECLARE_COMPLETION
        complete_and_exit()或者complete() 
    接收completion的一方：
        wait_for_completion();等待对方完成，未完成则睡眠
        wait_for_completion_timeout()在上面的基础上，加入了超时，超过时间自动唤醒。
相关文档：
    http://www.ibm.com/developerworks/cn/linux/l-synch/part1/index.html
    http://www.ibm.com/developerworks/cn/linux/l-synch/part2/index.html
    Linux\Kernel\学习资料\linux设备驱动归纳总结（四）：5_SMP下的竞态和并发.pdf
</code></pre><p>实践之semaphore的使用：<br>    以am335x用i2c连接的pca9552芯片驱动为例。<br>    这个芯片，一共有16路led输出。<br>    驱动会针对每个led输出，都用INIT_WORK创建各自的work。<br>    当用户在/sys/class/leds下操作的时候，最终就会去调用pca955x_led_work这个workqueue的work。<br>    pca955x_led_work代码如下：</p>
<pre><code>static void pca955x_led_work(struct work_struct *work)
{
struct pca955x_led *pca955x;
u8 ls;
int chip_ls;    /* which LSx to use (0-3 potentially) */
int ls_led;    /* which set of bits within LSx to use (0-3) */

if (down_interruptible (&amp;pca95xx_semaphore))
    return;

pca955x = container_of(work, struct pca955x_led, work);

chip_ls = pca955x-&gt;led_num / 4;
ls_led = pca955x-&gt;led_num % 4;

ls = pca955x_read_ls(pca955x-&gt;client, chip_ls);            //先读取

switch (pca955x-&gt;brightness) {                //更改
case LED_FULL:
    ls = pca955x_ledsel(ls, ls_led, PCA955X_LS_LED_ON);
    break;
case LED_OFF:
    ls = pca955x_ledsel(ls, ls_led, PCA955X_LS_LED_OFF);
    break;
default:
    break;
}

pca955x_write_ls(pca955x-&gt;client, chip_ls, ls);            //再写入

up(&amp;pca95xx_semaphore);
}
假设在用户空间，用户在一个脚本里面，顺序执行操作led的命令：
echo 255 &gt; /sys/class/leds/ledpad0-0/brightness
echo 255 &gt; /sys/class/leds/ledpad0-1/brightness
echo 255 &gt; /sys/class/leds/ledpad0-2/brightness
...
echo 255 &gt; /sys/class/leds/ledpad0-15/brightness
一共有15个workqueue内核线程在跑。
在不是用sempahore机制的前提下。因为顺序执行，cpu速度较快，其实几乎每次i2c操作（除了开头的一次），都会导致睡眠。
睡眠导致对应的workqueue线程换出，换入了下一个workqueue线程。
从而导致，某个workqueue线程在尚未完全做好读/改/写的操作之前，就被别的workqueue插入。
打了个log可以看到：（以led12和led13两颗led为例）
read begin led_num=12 chip_ls=3    
        &lt;----led12 i2c_smbus_read_byte_data()操作睡眠，导致换到led13的workqueue执行
read begin led_num=13 chip_ls=3
        &lt;----led13 i2c_smbus_read_byte_data()操作睡眠，导致换到led12的workqueue执行，此时led12睡醒了，可以继续进行i2c读操作
read end led_num=12 chip_ls=3 ls=0x55
write begin led_num=12 chip_ls=3 ls=0x54
        &lt;----led12 i2c_smbus_write_byte_data()操作睡眠，导致换到led13的workqueue执行，此时led13睡醒了，可以继续进行i2c读操作
read end led_num=13 chip_ls=3 ls=0x55
write begin led_num=13 chip_ls=3 ls=0x51
        &lt;----led13 i2c_smbus_write_byte_data()操作睡眠，导致换到led12的workqueue执行，此时led12睡醒了，可以继续进行i2c写操作
write end led_num=12 chip_ls=3 ls=0x54
write end led_num=13 chip_ls=3 ls=0x51
照理说，正确的顺序是：
read led_num=12 chip_ls=3 ls=0x55
write led_num=12 chip_ls=3 ls=0x54
read led_num=13 chip_ls=3 ls=0x54
write led_num=13 chip_ls=3 ls=0x50
也就是先做完led12的事情，再做led13的事情。
但实际上，上面没有锁保护的情况下，可以看到，led12还没开始写，led13就来读了。临界区的完整性被破坏了。
需要一个总的锁，来保证每个workqueue的操作，是原子的。（涉及持锁睡眠？）
spinlock在单核cpu上，作用仅仅是禁用抢占。抢占是针对不同的优先级的用户进程之间而言的。
这里的情形，是几个内核线程之间的关系。这时候关抢占是一点用没有的。
用semaphore，有效。
</code></pre>
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/07/28/size-t和ssize-t的使用/" rel="next" title="size_t和ssize_t的使用">
                <i class="fa fa-chevron-left"></i> size_t和ssize_t的使用
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/07/28/内存管理/" rel="prev" title="内存管理">
                内存管理 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Semiyd</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives">
                
                    <span class="site-state-item-count">57</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">27</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
            </nav>
          

          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Semiyd</span>

  

  
</div>




  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> v3.7.1</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://theme-next.org">NexT.Muse</a> v6.3.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.3.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.3.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.3.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.3.0"></script>



  



  










  





  

  

  

  

  
  

  

  

  

  

  

</body>
</html>
